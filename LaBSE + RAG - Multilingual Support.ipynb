{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06416ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e27eb700",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sentence-transformers in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: emoji in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.7.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence-transformers) (4.31.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence-transformers) (2.0.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence-transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence-transformers) (0.16.4)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.0)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.5.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.29.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.1)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk->sentence-transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchvision->sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a79cb033",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: fasttext in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.9.2)\n",
      "Requirement already satisfied: pybind11>=2.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from fasttext) (2.10.4)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from fasttext) (67.7.2)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from fasttext) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88ec0838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: evaluate in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: jiwer in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (3.0.2)\n",
      "Requirement already satisfied: rouge_score in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from evaluate) (2.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from evaluate) (1.24.3)\n",
      "Requirement already satisfied: dill in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from evaluate) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from evaluate) (2.29.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from evaluate) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from evaluate) (2023.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from evaluate) (0.16.4)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: responses<0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jiwer) (8.1.3)\n",
      "Requirement already satisfied: rapidfuzz==2.13.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jiwer) (2.13.7)\n",
      "Requirement already satisfied: absl-py in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (12.0.0)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (5.4.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk->rouge_score) (2023.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate jiwer rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d7337da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "m2 = SentenceTransformer('sentence-transformers/LaBSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c521f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = <openai-key>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e38069",
   "metadata": {},
   "source": [
    "### Dataset Cleaning and Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f44cc407",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset.txt', 'r') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "data = data.replace('\\n\\n','\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f18084fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.split('---')\n",
    "\n",
    "for i in range(0, len(data)):\n",
    "    if i==4:\n",
    "        data[i] = data[i].replace('\\n**', '\\n###').replace('**','')\n",
    "    elif i==3:\n",
    "        data[i] = data[i].replace('**','')\n",
    "    else:\n",
    "        data[i] = data[i].replace('**','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e016f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_ans = dict()\n",
    "for i in range(0, len(data)):\n",
    "    temp = data[i]\n",
    "    temp = temp.split('\\n###')\n",
    "    \n",
    "    for j in range(1, len(temp)):\n",
    "        tp = temp[j].split('\\n')\n",
    "        ques_ans[tp[0]] = \" \".join(tp[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f84d6d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qa_dict = dict()\n",
    "qa_dict['title'] = []\n",
    "qa_dict['text'] = []\n",
    "\n",
    "for key, value in ques_ans.items():\n",
    "    qa_dict['title'].append(key)\n",
    "    qa_dict['text'].append(value)\n",
    "    \n",
    "qa_df = pd.DataFrame.from_dict(qa_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbe37a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'text'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# You can load a Dataset object this way\n",
    "dataset = Dataset.from_pandas(qa_df)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5413dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import emoji\n",
    "def get_re_compiler_list_words(words_list):\n",
    "    compiled_str = r''\n",
    "    for i, word in enumerate(words_list):\n",
    "        if i == len(words_list) - 1:\n",
    "            compiled_str = compiled_str + r'\\b' + word + r'\\b'\n",
    "        else:\n",
    "            compiled_str = compiled_str + r'\\b' + word + r'\\b | '\n",
    "    r = re.compile(compiled_str, flags=re.I | re.X)\n",
    "\n",
    "    return r\n",
    "\n",
    "\n",
    "def get_compiler_removed_stopwords():\n",
    "    stopword_list = ['follow', 'channel', 'news', 'source', 'breaking', 'tv', 'watch', 'video', 'support', 'subscribe',\n",
    "                     'share', 'link', 'comment', 'download', 'free', 'post', 'click', 'online', 'tube', 'call', 'plz',\n",
    "                     'donate', 'help', 'shared', 'pls', 'sms', 'likes', 'copy', 'following', 'retweet', 'website',\n",
    "                     'comments', 'notification', 'updates', 'play', 'pay', 'msg', 'quotes', 'block', 'posts', 'rekoooo',\n",
    "                     'sent', 'from', 'here', 'android']\n",
    "    r = get_re_compiler_list_words(stopword_list)\n",
    "\n",
    "    return r\n",
    "\n",
    "stop_words_regex = get_compiler_removed_stopwords()\n",
    "url_pattern = re.compile(r'(https?://[^\\s]+)')\n",
    "text_compile1 = re.compile(\"&#39;\")\n",
    "text_compile2 = re.compile('[-_[\\]{}~\\':;\"’‘()–\\n\\r<>@&*+!?•°.,\\\\\\/%=^$|#“”]+')\n",
    "ptrn = re.compile('[^a-z ]')\n",
    "\n",
    "def get_emoji_regexp():\n",
    "    # Sort emoji by length to make sure multi-character emojis are\n",
    "    # matched first\n",
    "    emojis = sorted(emoji.EMOJI_DATA, key=len, reverse=True)\n",
    "    pattern = u'(' + u'|'.join(re.escape(u) for u in emojis) + u')'\n",
    "    return re.compile(pattern)\n",
    "\n",
    "def remove_emoji(text):\n",
    "    outp = get_emoji_regexp().sub(u'', str(text))\n",
    "    return outp\n",
    "\n",
    "def remove_mentions_and_hashtag(text):\n",
    "    \n",
    "    outp = \" \".join(filter(lambda x: x[0] not in ['#', '@'], text.split()))\n",
    "    return outp\n",
    "\n",
    "def remove_unnecessary_text(example):\n",
    "    text = example['title']\n",
    "    outp = url_pattern.sub('', text)\n",
    "    outp = stop_words_regex.sub('', outp)\n",
    "    outp = remove_mentions_and_hashtag(remove_emoji(outp))\n",
    "    outp = text_compile1.sub('', outp)\n",
    "    outp = text_compile2.sub('', outp)\n",
    "    \n",
    "    example['clean_title'] = outp\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "966180d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sent_check2(example):\n",
    "    \n",
    "    output = np.zeros([768,], dtype=np.float32)\n",
    "    try:\n",
    "        sent_embed = m2.encode(example['clean_title'])\n",
    "        output = sent_embed\n",
    "    except:\n",
    "        print(\"Error\")\n",
    "        \n",
    "    example['embeddings'] = output\n",
    "    \n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8489c404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(remove_unnecessary_text)\n",
    "dataset = dataset.map(sent_check2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a7513ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b45af8631d4555941bdaf53b4f27a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'text', 'clean_title', 'embeddings'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding FAISS Index for Retrieval via Embeddings\n",
    "dataset.add_faiss_index(column='embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a59999d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# Language Detection Model from NLLB\n",
    "\n",
    "import fasttext\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "model_path = hf_hub_download(repo_id=\"facebook/fasttext-language-identification\", filename=\"model.bin\")\n",
    "model = fasttext.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c771a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How can an NRI apply for a new PAN card?\"\n",
    "\n",
    "question_embedding = m2.encode(question)\n",
    "scores, retrieved_examples = dataset.get_nearest_examples('embeddings', question_embedding, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e35d7d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eng_Latn'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(question)[0][0].split('__')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93cf4f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = model.predict(question)[0][0].split('__')[-1]\n",
    "updated_message = [\n",
    "        {\"role\": \"system\", \"content\": \"I want you to act as a question answering bot which uses the context mentioned and answer in a concise manner and doesn't make stuff up.\"\n",
    "                                      \"You will answer question based on the context - {}\"\n",
    "                                      \"You will create content in {} language\"},\n",
    "        {\"role\": \"user\", \"content\": \"Now I want you to answer this question {}.\"},\n",
    "    ]\n",
    "\n",
    "updated_message[0]['content'] = updated_message[0]['content'].format(retrieved_examples['text'], language)\n",
    "updated_message[1]['content'] = updated_message[1]['content'].format(question)\n",
    "\n",
    "completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=updated_message,\n",
    "                                                      timeout=240, max_tokens=400, n=1, stop=None, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ff87bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To apply for a new PAN card as an NRI, follow these steps:\\n1. Visit the ABC app.\\n2. Navigate to Services > NRI Pan Card > Apply New PAN.\\n3. Select the required form of PAN card and proceed with the payment.\\n4. Our team will contact you to request the necessary documents, including your passport (any country) or OCI card, passport size photograph, and overseas address proof with zip code (such as Indian NRO/NRE account statement, overseas bank statement, or utility bill).'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ffa7bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "wer = load(\"rouge\")\n",
    "wer_score = wer.compute(predictions=['To apply for a new PAN card as an NRI, follow these steps:\\n1. Visit the ABC app.\\n2. Navigate to Services > NRI Pan Card > Apply New PAN.\\n3. Select the required form of PAN card and proceed with the payment.\\n4. Our team will contact you to request the necessary documents, including your passport (any country) or OCI card, passport size photograph, and overseas address proof with zip code.\\n5. Submit the requested documents to our team.\\n6. Your PAN card application will be processed, and the card will be delivered to your overseas address, including your Canadian address if applicable.'], references=[\"\"\"Here are the steps for *PAN CARD* processing. \n",
    "\n",
    "- Visit SBNRI app\n",
    "- Navigate to Services > NRI Pan Card > Apply New PAN\n",
    "- Select the required form of PAN card and proceed with the payment\n",
    "- Our team will get in touch with you to ask for the following documents:\n",
    "    - Passport(Any Country) / OCI Card\n",
    "    - Passport Size Photograph\n",
    "    - Overseas address proof with zip code (Supporting documents - Indian NRO/NRE Account statement or Overseas bank statement or Utility bill)\"\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f82ffde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.5909090909090909,\n",
       " 'rouge2': 0.3908045977011495,\n",
       " 'rougeL': 0.5568181818181819,\n",
       " 'rougeLsum': 0.5568181818181819}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wer_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee796c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the generated text with Word Error Rate (used as for transcription) and ROUGE Score for Translation Tasks.\n",
    "wer = load(\"wer\")\n",
    "rouge = load(\"rouge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6049e3",
   "metadata": {},
   "source": [
    "## Wrapping the Procedure in a function for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2918eeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def retrieve_output(example):\n",
    "    \n",
    "    question = example['Question']\n",
    "\n",
    "    question_embedding = m2.encode(question)\n",
    "    scores, retrieved_examples = dataset.get_nearest_examples('embeddings', question_embedding, k=10)\n",
    "    \n",
    "    language = model.predict(question)[0][0].split('__')[-1]\n",
    "    updated_message = [\n",
    "            {\"role\": \"system\", \"content\": \"I want you to act as a question answering bot which uses the context mentioned and answer in a concise manner and doesn't make stuff up.\"\n",
    "                                          \"You will answer question based on the context - {}\"\n",
    "                                          \"You will create content in {} language\"},\n",
    "            {\"role\": \"user\", \"content\": \"Now I want you to answer this question {}.\"},\n",
    "        ]\n",
    "\n",
    "    updated_message[0]['content'] = updated_message[0]['content'].format(retrieved_examples['text'], language)\n",
    "    updated_message[1]['content'] = updated_message[1]['content'].format(question)\n",
    "\n",
    "    completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=updated_message,\n",
    "                                                          timeout=240, max_tokens=400, n=1, stop=None, temperature=0)\n",
    "    example['retrieve_answer'] = completion['choices'][0]['message']['content']\n",
    "    \n",
    "    rg_score = rouge.compute(predictions=[example['retrieve_answer']], references=[example['Ideal Answer']])\n",
    "    example['rouge1'] = rg_score['rouge1']\n",
    "    example['rouge2'] = rg_score['rouge2']\n",
    "    example['rougeL'] = rg_score['rougeL']\n",
    "    example['rougeLsum'] = rg_score['rougeLsum']\n",
    "    \n",
    "    example['wer_score'] = wer.compute(predictions=[example['retrieve_answer']], references=[example['Ideal Answer']])\n",
    "    \n",
    "    gold_answer = m2.encode(example['Ideal Answer'])\n",
    "    predicted_answer = m2.encode(example['retrieve_answer'])\n",
    "    \n",
    "    example['cosine_similarity'] = cosine_similarity([gold_answer, predicted_answer])[0][0]\n",
    "    \n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a04ded9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset csv (/home/ec2-user/.cache/huggingface/datasets/csv/default-9a0891180e715608/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff9c285b157432c862130acce7e8b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "test_dict = load_dataset('csv', data_files='test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4d1eee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Question', 'Ideal Answer', 'retrieve_answer', 'rouge1', 'rouge2', 'rougeL', 'rougeLsum', 'wer_score', 'cosine_similarity'],\n",
       "        num_rows: 34\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fbf3a932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/34 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dict = test_dict.map(retrieve_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0b27644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Question', 'Ideal Answer', 'retrieve_answer', 'rouge1', 'rouge2', 'rougeL', 'rougeLsum', 'wer_score', 'cosine_similarity'],\n",
       "        num_rows: 34\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21287fc6",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20218318",
   "metadata": {},
   "source": [
    "### Average Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5aa46c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000017530777"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Higher Cosine Similarity shows better retrieved results based on semantics of the content.\n",
    "np.average(test_dict['train']['cosine_similarity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f6c2b",
   "metadata": {},
   "source": [
    "### Average WER Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3416c8b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7302871304448888"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word by Word Matching of results is not good enough\n",
    "np.average(test_dict['train']['wer_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c069ecb1",
   "metadata": {},
   "source": [
    "### Average Rouge Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61011109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6106952600891115"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROUGE-N (N-gram) scoring - 1-gram\n",
    "np.average(test_dict['train']['rouge1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c967e2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4811727442217518"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROUGE-N (N-gram) scoring - 2-gram\n",
    "np.average(test_dict['train']['rouge2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e312607b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5594129935022545"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROUGE-L (Longest Common Subsequence) scoring - Sentence Level\n",
    "np.average(test_dict['train']['rougeL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "960d6b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5823378441220609"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROUGE-L (Longest Common Subsequence) scoring - Summary Level\n",
    "np.average(test_dict['train']['rougeLsum'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
